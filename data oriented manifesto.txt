The programming community might just be one of the least scientific communities out there. It's understandable, writing a million lines of code in one paradigm then rewriting it in another paradigm just to see which is better in that specific case is a pretty hard sell. Therefore, every decision about how to program is based almost entirely on theory. Programming is still a relatively new field, so experience in it is still relatively low. Unfortunately, I'm not much better myself, having been a programmer for only 11 or so years. But still, I've spent countless hours contemplating the fundamentals of programming paradigms, including their problems and the causes of said problems. Hopefully this is enough, at least for now, for my thoughts to be respectable.

Anyone who has spent even a second in this community will know the paradigm that completely dominates everything: OOP. It needs no introduction, but it does not a solid definition. For the purposes of this work, my definition of an object-oriented program is: a program made of objects which achieve goals mainly by calling methods in other objects.

I'd love to give one big, fundamental reason for why OOP sucks, and though I can (it prioritizes the way humans think over the way programming should work), that doesn't directly explain why it's so bad. OOP is death by a thousand cuts, with countless tiny problems slowly degrading your productivity as scale increases. However, there's still one major problem that trumps all others, and it all has to do with control flow. It's the most important aspect of a program, which becomes obvious if you think for even just a second. When a user clicks a button, they don't care about the factory facotries or all the observer patterns that you use, they care about the sequence of action that occurs.

And here comes the problem: OOP is built off the idea that control flow doesn't matter. When you add a call to a method, in theory, you don't have to worry about that method's control flow because all the entangled managers and whatnot will theoretically handle everything. In reality, though, adding a call to an existing method is a huge gamble, because there's no telling what flags, events, and other systems will be affected.

It might seem excessive to say that OOP completely disregards control flow, but hopefully I can prove it. Even back when OOP was still Alan Kay's original vision, it still undeniably assumed that control flow doesn't matter. And thought processes like this do have visible effects, such as inheritance in languages like Java ensuring that almost every variable has possibly modified control flow. The whole point of OOP is that, instead of a call graph of functions, you can think of your program on an object-to-object bases.

Although, there's something kinda strange going on here. If you think about the actual mechanics of what you're doing, OOP and procedural are mechanically identical (except for inheritance). In one, you effectively have `funtionName(arg1, arg2, ...)`, and in the other you have `arg1.functionName(arg2, ...)`. C++ literally transforms the second example into the first, because every single thing that you can do in OOP (again, except inheritence) can be recreated one to one with procedural code. And I don't mean you can accomplish the same tasks in both, all you have to do to change OOP into procedural is to swap every method with a function and every object with a struct. So this brings up an interest question, why do many people (including me) say that OOP is better / worse than procedural when they're actually the same thing? As is often the case, the question is technically flawed. Yes they're mechanically identical, but they're extremely different mentally.

Let's take a quick detour. You have a sort of "working memory", which is an extremely short-term memory where you store what you're thinking at any given point in time. This working memory is extremely small, and obviously can't fit the entire inner workings of a program. Therefore, you have to take shortcuts that allow you to consider other parts of the program that deal with what you're actually working on. Programming paradigms can be thought of as a way to represent the important details of the program is a way that easily fits in your working memory. And this is where prodecural and OOP differ. Even though it's mechanically the same, the way the code is represented completely transforms the way you think of a program. Everything about OOP, including its design, community, and your own view of a program is telling you that you need to think of the program on an object-to-object bases. As this clearly shows, OOP literally goes out of its way to hide the program's control flow from you.

So lets do a little recap. I'm saying that control flow is extremely important for software development (and that's an understatement), please take a minute to check if you agree. I'm also saying that OOP fundamentally disregards control flow, and again, please take a minute to check if you agree. And if you do agree to both statements, you have to agree that OOP is fundamentally flawed. But this is still just theory, does it have any effect in the real world?

Look back at the last time you programmed with OOP, I can pretty much guarantee it went like this: you set everything up with an ideal system of whatever design patterns you want, and with some luck, it might even mostly work without any structural changes. But then comes the modifications and new features. Maybe you try to restructure everything to accomodate, or maybe you try to work the additions into the existing framework. But either way, there's always two stages here: the idealism stage where you build the code, tring to follow OOP's rules, and the reality stage where you use a debugger to fix the control flow and actually make it work.

When adding a new feature, you have to add any new associated data, then add the control flow for the feature. This cannot be changed. You're supposed to work on an object-to-object bases, but you actually jump from object to object whenever you add a feature. Again, you cannot change the fact that you have to add features one control flow at a time. This makes basically every OOP advocate a hypocrite, how many of them preach techniques that focus on one object at a time, when in reality they themselves add features one control flow at a time? Like I said near the beginning, OOP focuses entirely on how humans think instead of how programming actually works, but that bring up a question, how does programming actually work then?

Programming is where you have data, and you update the data. That's all it is. Yes you can (and should) add more to help curve the effects of scale, but that's the fundamentals of what programming actually is. OOP hinders your ability to have data, with it being haphazardly spread among objects where everything is private, and it hinders your ability to update data, since you're constrained to the update methods that were created way before you actually knew what those updates would need to be. Ideally, your programming paradigm should focus on defining and updating data in the most practical way possible. Defining data is never actually hard, just nest structs and enums as much as needed.
