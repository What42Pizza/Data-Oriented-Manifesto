Let's talk about the Open-Closed principle, where code should be "open to extension but closed to modification". This idea is absolutely ridiculous, most obviously because there's a nearly infinite number of future extensions that could be needed. But even if you're only focusing on some extensions that you could need, you'll inevitably be sometimes solving problems you'll never need to in the first place. I've seen people saying that premature optimization is the root of all evil, but no one ever talks about prematurely fixing problems before they're actually problematic. Unnecessary technical debt should be avoided at all costs. And if you don't agree, just let me rephrase it: you should avoid doing unnecessary work that can only result in more unnecessary work at all costs. But that's not even the only problem with the Open-Closed principle, and even if you manage to only add technical debt that ends up being justified, the Open-Closed principle is still completely backwards. The whole point of it is that it allows you to avoid modifying existing code, but how often does that work out? How many people have actually been able to avoid modifying existing code because of this principle? It isn't even possible to follow the Open-Closed principle, and the only real solution here is to make code that can be easily modified.

You'd probably guess that I would say that OOP is the biggest problem within the programming community, but that's actually not the case. There's a much worse problem, which is that we get way too excited about new and shiny features, tools, design patterns, etc. Just look at the earliest Rust game engines, they were so eager to use Rust's new and shiny features that they forgot to actually be good. How many times have you yourself shoved in a design pattern you just learned of just because you thought it was really cool and you wanted an excuse to use it? How many systems are outrageously overengineered just for the sake of feeling professional? How many frameworks have been created just because there was this one really cool feature that its creator wanted to have? I sure know that I'm often guilty of doing something because it's cool, and I've been guilty ever since I learned what a function is. This isn't actually very harmful as long as you can recognize that it's happening and can stop it when needed, but it's extremely dangerous when it's happening subconsciously. How much technical debt exists just because someone thought that their way of implementing something was really cool? How many layers of abstraction only exist because the person creating it thought it was cool? This might not have sounded like a big problem at first, but its consequences are close to dooming humanity. Does a car's throttle really need 256,600 lines of code? Apparently, someone at Toyota thought so (https://users.ece.cmu.edu/~koopman/pubs/koopman14_toyota_ua_slides.pdf p18).

As you've seen yourself, I clearly hate OOP. Despite that, though, I have a confession to make... I use OOP in small quantities. Yes, this may be shocking, but I've found that there are times when using OOP is just fine. Go back to what I was saying about working memory, and how programming paradigms are just ways to represent the important details of a program in a way that easily fits in working memory. Now consider this: if a subsection of code is small enough that its entirety can fit within your working memory, does it really matter what paradigm you're using? This might also be shocking, but I'd be willing to say that OOP does have some benefits. Mostly, it makes parts of code less daunting to work with. If you have a small section of code where OOP gives benefits without any weaknesses, why not use it?

Anyways, there are a few sillier things I need to get off my chest. It's ridiculous that some programmers say that declarative programming exists. Come on, just look at any "declarative code". It's imperative code just written pretentiously. This is the opposite of OOP vs procedural because imperative and declarative are mechanically different but mentally the same. Also, I didn't want to put this in part 2, but the definition "programming is just defining and updating data" just proves ever further that OOP is fundamentally wrong. It hinders your ability to have data, with it being haphazardly spread among objects where everything is private, and it hinders your ability to update data, since you're constrained to the update methods that were created way before you actually knew what those updates would need to be. Also, tabs are better than spaces, this is non-negotiable.

Finally, let's get back to "working memory". How much more of it do you think you'd need to be as smart as Einstein? Ten times more? A hundred times more? Probably not, I'd say it's more like 3x. Just imagine the largest equation you can fit in your working memory, then imagine if you could just as easily fit and manipulate three of those. That would be an unbelievably good upgrade, and my point is that even a small increase in working memory is extremely useful. The more working memory you have, the smarter you are. But there's another way to think about this: the less working memory you need, the smarter you effectively are. For example, what if the largest equation you can currently fit suddenly only took up one third of the space? You can do the same with code. I'd bet that you agree that good variable and function names are important to have, and this completely explains why. You don't have to keep in your head stuff like "t means total", which frees up room to think about more important details. If you put more space between functions, you don't have to have a mental note of where each function starts and ends. If you have consistent formatting, you don't have to bring the text into your working memory. Even if it only has to occupy your mind for a fraction of a second, it still has to kick out other data which is likely more important. Like I said in the beginning, I've spent countless hours thinking about details like this.

I'd love to end this by telling you to try out every programming style and substyle to figure out what actually works for your situation, but unfortunately, that's just not practical. However, I can still give you this advice: instead of fixing problems that you suspect will exist in the future, learn to fix problems as they start to pop up. And instead of adding complexity because it seems like the best thing to do, figure out what complexity is absolutely required. This also applies if you continue to OOP, which you likely don't even have a choice in.